{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run everything under Preprocessing and modeling the data, filtration filter, and making the feature matrix first. Then come up and run the load data sub section.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import statistics\n",
    "import os\n",
    "import scipy\n",
    "from statistics import median\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor,RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import datasets\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import permutation_test_score\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy import stats, integrate\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.svm import SVC \n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Initiate ONLY ONCE before running time windows**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font color='red'>Final scores will reset if you run this through each time window iteration</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create data_frame\n",
    "scores_df = pd.DataFrame(columns = ['Time Window (sec)', 'SVM', 'K-NN', 'Random Forest']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Input Desired Parameters Below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sliding window size (900 for 30sec)\n",
    "def window_size():\n",
    "    return 900;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "#overlap of sliding window = 20% of sliding window\n",
    "def overlap(w_s):\n",
    "    return int(.8 * w_s);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window():\n",
    "    return 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peak_threshold():\n",
    "    #changed from 32\n",
    "    return 20;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_radius():\n",
    "    #changed from 50\n",
    "    return 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>change file names accordingly</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/opt/conda/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3506: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  **kwargs)\n",
      "/opt/conda/lib/python3.7/site-packages/numpy/core/_methods.py:186: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "/opt/conda/lib/python3.7/site-packages/numpy/core/_methods.py:209: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/lib/python3.7/site-packages/numpy/core/_methods.py:217: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n"
     ]
    }
   ],
   "source": [
    "#loops through folder and gets each file then directs to main\n",
    "directory = os.fsencode(\"./interpolatedFiles\")\n",
    "\n",
    "w_s = window_size()\n",
    "ovl = overlap(w_s)\n",
    "s_w = sliding_window()\n",
    "p_t = peak_threshold()\n",
    "t_r = threshold_radius()\n",
    "\n",
    "\n",
    "feat_matrix_key= [['id', 'activity', 'sacc mean', 'sacc var', 'sacc std', 'sacc-up', 'sacc-up-right', 'sacc-right', 'sacc-down-right', 'sacc-up-down', 'sacc-down-left', 'sacc-left', 'sacc-left-up', 'fixa dura mean', 'fixa dura var', 'fixa dura std', 'fixa rate', 'slope', 'dispersion mean', 'fixation count']]\n",
    "feat_matrix = []\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "    filename = os.fsdecode(file)\n",
    "    if filename.endswith(\".csv\"): \n",
    "        eyedata_file = './interpolatedFiles/%s' % filename\n",
    "        eye_data = pd.read_csv(eyedata_file, encoding = \"utf-8\")\n",
    "        rawdata = np.asarray(eye_data)\n",
    "\n",
    "        #sliding window \n",
    "        data_id = 0\n",
    "        name = filename[4:-4]\n",
    "        i=0\n",
    "        for i in range (0,len(rawdata), i+ovl):\n",
    "            start_ind = i\n",
    "            end_ind = start_ind + w_s\n",
    "            sliced_pd = eye_data.iloc[start_ind:end_ind]\n",
    "            sliced_np = rawdata[start_ind:end_ind, :]\n",
    "            main(sliced_pd, sliced_np, s_w, p_t, t_r, data_id, name, start_ind)\n",
    "            data_id +=1 \n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feat_df = pd.DataFrame(feat_matrix)\n",
    "feat_df.columns = ['id', 'activity', 'sacc mean', 'sacc var', 'sacc std', 'sacc-up', 'sacc-up-right', 'sacc-right', 'sacc-down-right', 'sacc-up-down', 'sacc-down-left', 'sacc-left', 'sacc-left-up', 'fixa dura mean', 'fixa dura var', 'fixa dura std', 'fixa rate', 'slope', 'dispersion mean', 'fixation count']\n",
    "#fill na with mean\n",
    "feat_df.fillna(feat_df.mean(), inplace=True)\n",
    "feat_df.drop(['id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = model_main(feat_df, scores_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time Window (sec)</th>\n",
       "      <th>SVM</th>\n",
       "      <th>K-NN</th>\n",
       "      <th>Random Forest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.459321</td>\n",
       "      <td>0.379095</td>\n",
       "      <td>0.458435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.455835</td>\n",
       "      <td>0.399369</td>\n",
       "      <td>0.459772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.474988</td>\n",
       "      <td>0.396216</td>\n",
       "      <td>0.466646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.482053</td>\n",
       "      <td>0.399022</td>\n",
       "      <td>0.472824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.494347</td>\n",
       "      <td>0.419658</td>\n",
       "      <td>0.487356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>45.0</td>\n",
       "      <td>0.524899</td>\n",
       "      <td>0.441763</td>\n",
       "      <td>0.508375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>45.0</td>\n",
       "      <td>0.509506</td>\n",
       "      <td>0.426370</td>\n",
       "      <td>0.504935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time Window (sec)       SVM      K-NN  Random Forest\n",
       "0               30.0  0.459321  0.379095       0.458435\n",
       "1               30.0  0.455835  0.399369       0.459772\n",
       "2               30.0  0.474988  0.396216       0.466646\n",
       "3               30.0  0.482053  0.399022       0.472824\n",
       "4               30.0  0.494347  0.419658       0.487356\n",
       "5               45.0  0.524899  0.441763       0.508375\n",
       "6               45.0  0.509506  0.426370       0.504935"
      ]
     },
     "execution_count": 710,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Case Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Only run this if you need to test a single file to tweak code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(eye_data, rawdata, sliding_window, peak_threshold, threshold_radius, data_id, activity_name, start_ind):\n",
    "    fixations = get_fixations(rawdata, sliding_window, peak_threshold, threshold_radius)\n",
    "    fixind_array = fix_indicate(rawdata, fixations)\n",
    "    fix_array = make_fixarray(eye_data, fixind_array, start_ind)\n",
    "    #feat_array = make_featarray(fix_array, sliding_window, data_id, activity_name)\n",
    "    return fix_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(eye_data, rawdata, sliding_window, peak_threshold, threshold_radius, data_id, activity_name, start_ind):\n",
    "    fixations = get_fixations(rawdata, sliding_window, peak_threshold, threshold_radius)\n",
    "    fixind_array = fix_indicate(rawdata, fixations)\n",
    "    fix_array = make_fixarray(eye_data, fixind_array, start_ind)\n",
    "    feat_array = make_featarray(fix_array, sliding_window, data_id, activity_name)\n",
    "    return feat_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-77c5fac60171>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mfix_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtesting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msliced_pd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msliced_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_ind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mfix_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfix_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mfix_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfix_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfix_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "#one act, one participant\n",
    "\n",
    "test = []\n",
    "# load data (just one file)\n",
    "name = \"P09_READ.csv\"\n",
    "eyedata_file = './interpolatedFiles/%s' % name\n",
    "eye_data = pd.read_csv(eyedata_file, encoding = \"utf-8\")\n",
    "data_id = 0\n",
    "name = filename[4:-4]\n",
    "rawdata = np.asarray(eye_data)\n",
    "\n",
    "#x, y = rawdata.T\n",
    "#plt.scatter(x,y)\n",
    "#plt.show()\n",
    "\n",
    "i=0\n",
    "for i in range (0,len(rawdata), i+ovl):\n",
    "    start_ind = i\n",
    "    end_ind = start_ind + w_s\n",
    "    sliced_pd = eye_data.iloc[start_ind:end_ind]\n",
    "    sliced_np = rawdata[start_ind:end_ind, :]\n",
    "    fix_arr = testing(sliced_pd, sliced_np, 5, 32, 50, data_id, name, start_ind)\n",
    "    fix_arr = np.asarray(fix_arr)\n",
    "    fix_arr = fix_arr[:, 0:2]\n",
    "    x,y = fix_arr.T\n",
    "    plt.scatter(x,y)\n",
    "    plt.show()\n",
    "    \n",
    "    x,y = sliced_np.T\n",
    "    plt.scatter(x,y)\n",
    "    plt.show()\n",
    "    data_id +=1 \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dummy Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(feat_df):\n",
    "    #factorize df\n",
    "    obj_df_pre = feat_df.copy()\n",
    "    factor = pd.factorize(obj_df_pre['activity'])\n",
    "    obj_df_pre.activity = factor[0]\n",
    "    definitions = factor[1]\n",
    "\n",
    "    return obj_df_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_matrix(obj_df_pre):\n",
    "    interp_feat_matrix = np.asarray(obj_df_pre)\n",
    "    return interp_feat_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [],
   "source": [
    "def starndardize_df(obj_df_pre):\n",
    "    #standardize df\n",
    "    scaler = MinMaxScaler() \n",
    "    obj_df = scaler.fit_transform(obj_df_pre)\n",
    "    return obj_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_feat(features):\n",
    "    Standardisation = preprocessing.StandardScaler() \n",
    "  \n",
    "    # Scaled feature \n",
    "    feat_std = Standardisation.fit_transform(features) \n",
    "        \n",
    "    return feat_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training & Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feat_lab(obj_df, interp_feat_matrix):\n",
    "    \n",
    "    #split training and testing data\n",
    "    labels = []\n",
    "    features = []\n",
    "\n",
    "    for featarr in interp_feat_matrix:\n",
    "        labels.append(featarr[0])\n",
    "        features.append(featarr[1:])\n",
    "\n",
    "    np.asarray(labels)\n",
    "    np.asarray(features)\n",
    "    \n",
    "    #standardize features\n",
    "    Standardisation = preprocessing.StandardScaler() \n",
    "    # Scaled feature \n",
    "    feat_std = Standardisation.fit_transform(features) \n",
    "\n",
    "    features_arr = np.asarray(feat_std)\n",
    "    labels_arr = np.asarray(labels)\n",
    "    \n",
    "    return [features_arr, labels_arr]\n",
    "\n",
    "    #x is features, y is labels\n",
    "   # X_train, X_test, y_train, y_test = train_test_split(feat_std, labels, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create random forest model\n",
    "def create_forest():\n",
    "    forest_model = RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = None)\n",
    "    return forest_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create svm model\n",
    "def create_svm():\n",
    "    #Create a svm Classifier\n",
    "    svm_model = svm.SVC(gamma = 'auto', kernel='rbf', C = 10) # rbf Kernel\n",
    "    return svm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create knn model\n",
    "def create_knn():\n",
    "    #create Knn model\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=3)\n",
    "    return knn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Models Using Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit models using StratifiedKfold Cross validation and retrieve F1-score averaged over 10 folds\n",
    "def fit_models(feat_lab, forest_model, svm_model, knn_model):\n",
    "    scores_forest = []\n",
    "    scores_svm = []\n",
    "    scores_knn = []\n",
    "    \n",
    "    features_arr = feat_lab[0]\n",
    "    labels_arr = feat_lab[1]\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=10)\n",
    "    skf.get_n_splits(features_arr, labels_arr)\n",
    "\n",
    "    #StratifiedKFold(n_splits=10, random_state=None, shuffle=True)\n",
    "    for train_index, test_index in skf.split(features_arr, labels_arr):\n",
    "        X_train, X_test = features_arr[train_index], features_arr[test_index]\n",
    "        y_train, y_test = labels_arr[train_index], labels_arr[test_index]\n",
    "\n",
    "        # Train the model using the training sets\n",
    "        forest_model.fit(X_train,y_train)\n",
    "        svm_model.fit(X_train,y_train)\n",
    "        knn_model.fit(X_train,y_train)\n",
    "\n",
    "        #Predict Output\n",
    "        forest_pred = forest_model.predict(X_test)\n",
    "        svm_pred = svm_model.predict(X_test)\n",
    "        knn_pred= knn_model.predict(X_test)\n",
    "\n",
    "\n",
    "        #get f1 score\n",
    "        scores_forest.append(metrics.f1_score(y_test, forest_pred, average='micro'))\n",
    "        scores_svm.append(metrics.f1_score(y_test, svm_pred, average='micro'))\n",
    "        scores_knn.append(metrics.f1_score(y_test, knn_pred, average='micro'))\n",
    "        \n",
    "    avg_score_forest = statistics.mean(scores_forest)\n",
    "    avg_score_svm = statistics.mean(scores_svm)\n",
    "    avg_score_knn = statistics.mean(scores_knn)\n",
    "    \n",
    "    return [window_size()/30, avg_score_svm, avg_score_knn, avg_score_forest]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reporting F-1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_main(feat_df, scores_df):\n",
    "    \n",
    "    #preprocess \n",
    "    obj_df_pre = preprocess_df(feat_df)\n",
    "    interp_feat_matrix =  make_matrix(obj_df_pre)\n",
    "    # feat_std = standardize_feat(features)\n",
    "    obj_df = starndardize_df(obj_df_pre)\n",
    "    \n",
    "    #get features and labels\n",
    "    feat_lab = get_feat_lab(obj_df, interp_feat_matrix)\n",
    "    \n",
    "    #create models\n",
    "    forest_model = create_forest()\n",
    "    svm_model = create_svm()\n",
    "    knn_model = create_knn()\n",
    "    \n",
    "    #fit models using cross validation\n",
    "    new_row = fit_models(feat_lab, forest_model, svm_model, knn_model)\n",
    "    \n",
    "    #append row\n",
    "    scores_df.loc[len(scores_df)] = new_row\n",
    "    \n",
    "    return scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time Window (sec)</th>\n",
       "      <th>SVM</th>\n",
       "      <th>K-NN</th>\n",
       "      <th>Random Forest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.459321</td>\n",
       "      <td>0.379095</td>\n",
       "      <td>0.458435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time Window (sec)       SVM      K-NN  Random Forest\n",
       "0               30.0  0.459321  0.379095       0.458435"
      ]
     },
     "execution_count": 673,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create and fit random forest model\n",
    "forest_model = RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = None)\n",
    "forest_model.fit(X_train, y_train) \n",
    "\n",
    "# Predicting the Test set results\n",
    "forest_pred = forest_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.47105788423153694\n",
      "[[38  0  0 11  3  1  8  4]\n",
      " [ 0 58  0  2  3  1  2  3]\n",
      " [ 4  0 24  1 11 11  9  2]\n",
      " [13  2  0 31  0  1  4  9]\n",
      " [ 1  2 20  7 16  6  3  4]\n",
      " [ 2  4 11  5  7 29  6  4]\n",
      " [11  2  7  1 13  4 19  6]\n",
      " [ 8  5  0 13  0  1  7 21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.494     0.585     0.535        65\n",
      "         1.0      0.795     0.841     0.817        69\n",
      "         2.0      0.387     0.387     0.387        62\n",
      "         3.0      0.437     0.517     0.473        60\n",
      "         4.0      0.302     0.271     0.286        59\n",
      "         5.0      0.537     0.426     0.475        68\n",
      "         6.0      0.328     0.302     0.314        63\n",
      "         7.0      0.396     0.382     0.389        55\n",
      "\n",
      "    accuracy                          0.471       501\n",
      "   macro avg      0.459     0.464     0.460       501\n",
      "weighted avg      0.467     0.471     0.467       501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model accuracy for X_test   \n",
    "accuracy = forest_model.score(X_test, y_test)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "\n",
    "# creating a confusion matrix \n",
    "cm = confusion_matrix(y_test, forest_pred) \n",
    "print(cm)\n",
    "\n",
    "report = metrics.classification_report(y_test, forest_pred, digits=3)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.32861635220125784, 0.3160377358490566, 0.3380503144654088, 0.3113207547169811, 0.29874213836477986, 0.36163522012578614, 0.3333333333333333, 0.2908805031446541, 0.2861685214626391, 0.2893481717011129]\n"
     ]
    }
   ],
   "source": [
    "scores_forest = []\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "skf.get_n_splits(features_arr, labels_arr)\n",
    "\n",
    "#StratifiedKFold(n_splits=10, random_state=None, shuffle=True)\n",
    "for train_index, test_index in skf.split(features_arr, labels_arr):\n",
    "    X_train, X_test = features_arr[train_index], features_arr[test_index]\n",
    "    y_train, y_test = labels_arr[train_index], labels_arr[test_index]\n",
    "    \n",
    "    # Train the model using the training sets\n",
    "    forest_model.fit(X_train,y_train)\n",
    "\n",
    "    #Predict Output\n",
    "    forest_pred = forest_model.predict(X_test)\n",
    "    \n",
    "    #get f1 score\n",
    "    scores_forest.append(metrics.f1_score(y_test, forest_pred, average='micro'))\n",
    "    \n",
    "print(scores_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31541330453650096\n"
     ]
    }
   ],
   "source": [
    "avg_score_forest = statistics.mean(scores_forest)\n",
    "print(avg_score_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07651354 0.04873618 0.05250687 0.01696586 0.01509562 0.02591457\n",
      " 0.01656175 0.02224101 0.01754898 0.0272308  0.01604907 0.10924233\n",
      " 0.09378449 0.0924319  0.05177735 0.09779458 0.16782786 0.05177724]\n",
      "[ 4 10  6  3  8  7  5  9  1 17 14  2  0 13 12 15 11 16]\n"
     ]
    }
   ],
   "source": [
    "#feature importance\n",
    "importances = forest_model.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "print(importances)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign importance value to each feature\n",
    "feat_by_impt = {}\n",
    "\n",
    "i = 0\n",
    "for ind in indices:\n",
    "    feat = feat_df.columns[ind+1]\n",
    "    feat_by_impt[feat] = importances[i]\n",
    "    i+=1\n",
    "feat_by_impt = {k: v for k, v in sorted(feat_by_impt.items(), key=lambda item: item[1], reverse = True)}\n",
    "\n",
    "featlist_impt = list(feat_by_impt.keys())\n",
    "indices_desc = list(feat_by_impt.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Relative Importance')"
      ]
     },
     "execution_count": 566,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot important features\n",
    "plt.figure(1)\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "y_pos = np.arange(len(featlist_impt))\n",
    "y_pos = np.flip(y_pos)\n",
    "plt.yticks(y_pos, featlist_impt)\n",
    "plt.xlabel('Relative Importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Create a svm Classifier\n",
    "svm_model = svm.SVC(gamma = 'auto', kernel='rbf', C = 10) # Linear Kernel\n",
    "\n",
    "#Train the model using the training sets\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "svm_pred = svm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model accuracy for X_test   \n",
    "accuracy = svm_model.score(X_test, y_test)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "\n",
    "# creating a confusion matrix \n",
    "cm = confusion_matrix(y_test, svm_pred) \n",
    "print(cm)\n",
    "\n",
    "report = metrics.classification_report(y_test, svm_pred, digits=3)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3050314465408805, 0.32075471698113206, 0.3380503144654088, 0.30974842767295596, 0.27672955974842767, 0.3694968553459119, 0.3411949685534591, 0.32075471698113206, 0.31001589825119236, 0.35135135135135137]\n"
     ]
    }
   ],
   "source": [
    "scores_svm = []\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "skf.get_n_splits(features_arr, labels_arr)\n",
    "\n",
    "#StratifiedKFold(n_splits=10, random_state=None, shuffle=True)\n",
    "for train_index, test_index in skf.split(features_arr, labels_arr):\n",
    "    X_train, X_test = features_arr[train_index], features_arr[test_index]\n",
    "    y_train, y_test = labels_arr[train_index], labels_arr[test_index]\n",
    "    \n",
    "    # Train the model using the training sets\n",
    "    svm_model.fit(X_train,y_train)\n",
    "\n",
    "    #Predict Output\n",
    "    svm_pred = svm_model.predict(X_test)\n",
    "    \n",
    "    #get f1 score\n",
    "    scores_svm.append(metrics.f1_score(y_test, svm_pred, average='micro'))\n",
    "    \n",
    "print(scores_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_score_svm = statistics.mean(scores_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create Knn model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Train the model using the training sets\n",
    "knn_model.fit(X_train,y_train)\n",
    "\n",
    "#Predict Output\n",
    "knn_pred= knn_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model accuracy for X_test   \n",
    "accuracy = knn_model.score(X_test, y_test)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "\n",
    "# creating a confusion matrix \n",
    "cm = confusion_matrix(y_test, knn_pred) \n",
    "print(cm)\n",
    "\n",
    "report = metrics.classification_report(y_test, knn_pred, digits=3)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2688679245283019, 0.2610062893081761, 0.2830188679245283, 0.25471698113207547, 0.2358490566037736, 0.2940251572327044, 0.26572327044025157, 0.25, 0.2480127186009539, 0.2575516693163752]\n"
     ]
    }
   ],
   "source": [
    "scores_knn = []\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "skf.get_n_splits(features_arr, labels_arr)\n",
    "\n",
    "#StratifiedKFold(n_splits=10, random_state=None, shuffle=True)\n",
    "for train_index, test_index in skf.split(features_arr, labels_arr):\n",
    "    X_train, X_test = features_arr[train_index], features_arr[test_index]\n",
    "    y_train, y_test = labels_arr[train_index], labels_arr[test_index]\n",
    "    \n",
    "    # Train the model using the training sets\n",
    "    knn_model.fit(X_train,y_train)\n",
    "\n",
    "    #Predict Output\n",
    "    knn_pred= knn_model.predict(X_test)\n",
    "    \n",
    "    #get f1 score\n",
    "    scores_knn.append(metrics.f1_score(y_test, knn_pred, average='micro'))\n",
    "    \n",
    "print(scores_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_score_knn = statistics.mean(scores_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtration Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating 1D difference vector \n",
    "#m(after) - m(before) = difference in means of sliding windows\n",
    "#r = length of sliding windows\n",
    "\n",
    "#input is the array of x, y, exists & value of sliding window\n",
    "def difference_vector(eye_array, r): \n",
    "    \n",
    "    diff_vector = []\n",
    "    \n",
    "    #run through each array \n",
    "    for n in range(r, (len(eye_array) - r - 1)):\n",
    "        \n",
    "        m_before_x = 0\n",
    "        m_before_y = 0\n",
    "        m_after_x = 0\n",
    "        m_after_y = 0\n",
    "    \n",
    "        \n",
    "        for i in range(1, r):\n",
    "            #m_before is the avg of r (sliding window) values \n",
    "            try:\n",
    "                m_before_x += eye_array[n-i][0]/r\n",
    "                m_before_y += eye_array[n-i][1]/r\n",
    "                m_after_x += eye_array[n+i][0]/r\n",
    "                m_after_y += eye_array[n+i][1]/r\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "        diff_eq = math.sqrt((m_after_x - m_before_x)**2 + (m_after_y - m_before_y)**2)\n",
    "        \n",
    "        diff_vector.append(diff_eq)\n",
    "        \n",
    "    return np.asarray(diff_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input the difference vector\n",
    "#all peaks are detected with diff_vector\n",
    "#find values higher than preceding and following sample\n",
    "def find_peaks(diff_vector):\n",
    "    \n",
    "    shape = np.shape(diff_vector)\n",
    "    size_diffvect = shape[0]\n",
    "\n",
    "    #peak vector is same size as raw data. initialized as 0. just input values at indices with peaks\n",
    "    peak = [0] * size_diffvect\n",
    "    \n",
    "    #running through difference vector and inserting diff value if greater than point before and after\n",
    "    for n in range(0, size_diffvect-1):\n",
    "        if diff_vector[n] > diff_vector[n-1] and diff_vector[n] > diff_vector[n+1]:\n",
    "            peak[n] = diff_vector[n]\n",
    "            \n",
    "    return np.asarray(peak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r is sliding window\n",
    "#if more than one peak is found within a window of r values, highest peak kept\n",
    "def remove_close_peaks(peak_vector, r):\n",
    "\n",
    "    result_vect = peak_vector\n",
    "    \n",
    "    for n in range(r, result_vect.size - r - 1):\n",
    "        #if there is a peak at that index\n",
    "        if result_vect[n] != 0:\n",
    "            #run through that sliding window of peaks\n",
    "            for i in range(n-r, n-1):\n",
    "                #keep peak only if it is higher than selected peak\n",
    "                if result_vect[i] < result_vect[n]:\n",
    "                    result_vect[i] = 0\n",
    "            for i in range(n+1, n+r):\n",
    "                if result_vect[i] < result_vect[n]:\n",
    "                    result_vect[i] = 0\n",
    "                \n",
    "    return result_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add indices of peaks taller than given threshold in peak vector to a list\n",
    "def find_peak_indices(peak_vector, threshold):\n",
    "    peak_indices = []\n",
    "    \n",
    "    shape = np.shape(peak_vector)\n",
    "    size_peakvect = shape[0]\n",
    "\n",
    "    for n in range(0, size_peakvect-1):\n",
    "        if (peak_vector[n] > threshold):\n",
    "            peak_indices.append(n)\n",
    "            \n",
    "    return peak_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#estimate positions of fixations using median and join fixations that spatially close together given threshold\n",
    "#done iteratively... starting with fixations with shortest intermediate distance\n",
    "#inputs: peak indices & fixation\n",
    "#i am assuming that I don't have a fixation list? not sure if they do \n",
    "def estimate_fixations(peak_indices, rawdata, threshold_radius):\n",
    "    \n",
    "    res_indices = peak_indices.copy()\n",
    "\n",
    "    #initialize very negative so that it enters while loop\n",
    "    shortestdist = -9999999\n",
    "\n",
    "    #stops when there are no more distances shorter than threshold\n",
    "    while (shortestdist < threshold_radius): \n",
    "        #initialize fixation estimate array\n",
    "        fix_est = []\n",
    "\n",
    "        #add median estimate to fixation list. use all raw data sam\n",
    "         \n",
    "        #getting length\n",
    "        #go through range of peak indices. in one iteration, going from peak(n-1) to peak(1)\n",
    "        #(n=0 is spot for first peak index)\n",
    "        for n in range(1, len(res_indices) -1):\n",
    "            #x and y array that will later be used to compute median\n",
    "            fix_x_est = []\n",
    "            fix_y_est = []\n",
    "            \n",
    "            #finding actual index (indexing to peak index which represents place in raw data x and y position of peak)\n",
    "            for i in range(res_indices[n-1], res_indices[n]):\n",
    "                #append the x and y data points to be used for fixation median\n",
    "                fix_x_est.append(rawdata[i][0])\n",
    "                fix_y_est.append(rawdata[i][1])\n",
    "                \n",
    "            #this is median estimate of fixaiton but taking all points of peak range (peak(n-1) to peak(n))\n",
    "            fix_x_med = median(fix_x_est)\n",
    "            fix_y_med = median(fix_y_est)\n",
    "            \n",
    "            #it should be appending just \n",
    "            #append to fixation estimate 2d array\n",
    "            fix_est.append((fix_x_med, fix_y_med))\n",
    "            \n",
    "        fixest_array = np.asarray(fix_est)\n",
    "        \n",
    "        \n",
    "        #set shortest distance to inf\n",
    "        shortestdist = float('inf')\n",
    "        #calculate distance as euclidean norm bw current and previous fixation estimate. \n",
    "        #if shorter than current shortest distance, mark it as shortest and remember index\n",
    "        \n",
    "\n",
    "        for n in range(1, len(fixest_array) -1):\n",
    "            x_curr = fixest_array[n][0]\n",
    "            x_prev = fixest_array[n-1][0]\n",
    "            y_curr = fixest_array[n][1]\n",
    "            y_prev = fixest_array[n-1][1]\n",
    "            \n",
    "            eucl_dist = math.sqrt((x_curr - x_prev)**2 + (y_curr - y_prev)**2)\n",
    "           \n",
    "            if eucl_dist < shortestdist:\n",
    "                shortestdist = eucl_dist\n",
    "                \n",
    "                #n is the index in which the distance is smaller than the shortest distance... \n",
    "                #we're going to want to remove\n",
    "                index = n     \n",
    "                \n",
    "            #if shortest intermediate distance bw 2 fixations is shorter than threshold radius\n",
    "            #remove peak separating them, during next iteration they will be joined together\n",
    "        if shortestdist < threshold_radius:\n",
    "            del res_indices[index]\n",
    "    \n",
    "    #returning the peak_indices that have too short of distance bw\n",
    "    return(res_indices)\n",
    "    \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#retrieve fixation estimates \n",
    "#returns array with fixation indices (in form of peaks)\n",
    "def get_fixations(rawdata, sliding_window, peak_threshold, threshold_radius):\n",
    "    diff_vector = difference_vector(rawdata, sliding_window)\n",
    "    peaks = find_peaks(diff_vector)\n",
    "    fixed_peaks = remove_close_peaks(peaks, sliding_window)\n",
    "    peak_ind = find_peak_indices(peaks, peak_threshold)\n",
    "    fixations = estimate_fixations(peak_ind, rawdata, threshold_radius)\n",
    "    return fixations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create boolean array to indiciate if a given point is a fixation\n",
    "def fix_indicate(rawdata, fixations): \n",
    "    fixind_arr = []\n",
    "    for i in range(0, len(rawdata)):\n",
    "        if i in fixations:\n",
    "            fixind_arr.append(True)\n",
    "        else: \n",
    "            fixind_arr.append(False)\n",
    "    return fixind_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create array of x,y points of just fixation points\n",
    "def make_fixarray(eye_data, fixind_array, start_ind):\n",
    "\n",
    "    #copy of data frame\n",
    "    df_features = eye_data.copy()\n",
    "    df_features.reset_index(inplace=True)\n",
    "\n",
    "    #calculate times and put it into an array\n",
    "    currtime = 33 * start_ind\n",
    "    times = []\n",
    "    for index, row in df_features.iterrows():\n",
    "        times.append(currtime)\n",
    "        currtime += 33\n",
    "    timesarr = np.asarray(times)\n",
    "    \n",
    "    #add column of timestamp\n",
    "    df_features1 = pd.concat([df_features, pd.DataFrame(timesarr), pd.DataFrame(fixind_array)], axis=1)\n",
    "\n",
    "    \n",
    "    df_features1.columns = ['id', 'x', 'y', 'timestamp', 'fixation_bool']\n",
    "\n",
    "   \n",
    "    #filter df to get only fixation points\n",
    "    fixation_df = df_features1[(df_features1['fixation_bool'] == True)]\n",
    "    fixation_df = fixation_df.filter(['x', 'y', 'timestamp'])\n",
    "    \n",
    "    #array of just fixation peaks, timestamp, and boolean\n",
    "    fix_array = np.asarray(fixation_df)\n",
    "    \n",
    "    \n",
    "    return np.asarray(fix_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Feature Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2d array holding each data set's features\n",
    "#one array is one data set \n",
    "\n",
    "def main(eye_data, rawdata, sliding_window, peak_threshold, threshold_radius, data_id, activity_name, start_ind):\n",
    "    fixations = get_fixations(rawdata, sliding_window, peak_threshold, threshold_radius)\n",
    "    fixind_array = fix_indicate(rawdata, fixations)\n",
    "    fix_array = make_fixarray(eye_data, fixind_array, start_ind)\n",
    "    feat_array = make_featarray(fix_array, sliding_window, data_id, activity_name)\n",
    "    feat_matrix.append(feat_array)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create array of all features for model\n",
    "def make_featarray(fix_array, r, data_id, activity_name):\n",
    "    \n",
    "    res = {}\n",
    "    \n",
    "    res.update({\"id\": data_id, \"activity\": name})\n",
    "   \n",
    "    #array of mean, var, std of saccade size\n",
    "    saccsize_arr = sacc_size(fix_array, r)\n",
    "    saccsize_mean = saccsize_arr[0]\n",
    "    saccsize_var = saccsize_arr[1]\n",
    "    saccsize_std = saccsize_arr[2]\n",
    "    res.update({\"sacc mean\": saccsize_mean, \"sacc var\": saccsize_var, \"sacc std\": saccsize_std})\n",
    "    \n",
    "    #dictionary of counts of basic directions\n",
    "    directions = sacc_dir(fix_array, r)\n",
    "    compass_brackets = [\"sacc-up\", \"sacc-up-right\", \"sacc-right\", \"sacc-down-right\", \"sacc-up-down\", \"sacc-down-left\", \"sacc-left\", \"sacc-up-left\", \"sacc-up\"]\n",
    "    res.update(directions)\n",
    "    \n",
    "    #array of mean, var, std of fixation duration\n",
    "    fixdura_arr = fix_dura(fix_array)\n",
    "    fixdura_mean = fixdura_arr[0]\n",
    "    fixdura_var = fixdura_arr[1]\n",
    "    fixdura_std = fixdura_arr[2]\n",
    "    res.update({\"fixa dura mean\" : fixdura_mean,\"fixa dura var\" : fixdura_var, \"fixa dura std\": fixdura_std})\n",
    "    \n",
    "    #int value of fixation rate\n",
    "    fixat_rate = fixa_rate(fix_array)\n",
    "    res.update({\"fixa rate\": fixat_rate})\n",
    "    \n",
    "    #int value of fixation slope\n",
    "    slope_feat = slope(fix_array)\n",
    "    res.update({\"slope\" : slope_feat})\n",
    "    \n",
    "    #int value of mean of dispersion area distances\n",
    "    disparea_mean = disp_area(fix_array)\n",
    "    res.update({\"dispersion mean\" : disparea_mean})\n",
    "    \n",
    "    #int value of number of fixations\n",
    "    fix_countret = fix_count(fix_array)\n",
    "    res.update({\"fixation count\" :fix_countret})\n",
    "    \n",
    "    return list(res.values())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features for Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saccade Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating 1D difference vector \n",
    "#m(after) - m(before) = difference in means of sliding windows\n",
    "#r = length of sliding windows\n",
    "\n",
    "#input is the array of x and y & value of sliding window\n",
    "#returns saccade mean, std_dev, var\n",
    "def sacc_size(fix_array, r): \n",
    "        \n",
    "    fixsize_vect = []\n",
    "     \n",
    "    #run through array\n",
    "    for n in range(r, (len(fix_array) - r - 1)):\n",
    "        \n",
    "        m_before_x = 0\n",
    "        m_before_y = 0\n",
    "        m_after_x = 0\n",
    "        m_after_y = 0\n",
    "            \n",
    "        for i in range(1, r):\n",
    "            #m_before is the avg of r (sliding window) values \n",
    "            try:\n",
    "                m_before_x += fix_array[n-i, 0]/r\n",
    "                m_before_y += fix_array[n-i, 1]/r\n",
    "                m_after_x += fix_array[n+i,0]/r\n",
    "                m_after_y += fix_array[n+i, 1]/r\n",
    "            except:\n",
    "                continue\n",
    " \n",
    "        diff_eq = math.sqrt((m_after_x - m_before_x)**2 + (m_after_y - m_before_y)**2)\n",
    "        \n",
    "        fixsize_vect.append(diff_eq)\n",
    "        \n",
    "    fixsize_vect = np.asarray(fixsize_vect)\n",
    "        \n",
    "    #ret mean,var,std of fix sizes\n",
    "    sacc_mean = np.mean(fixsize_vect)\n",
    "    sacc_var = np.var(fixsize_vect)\n",
    "    sacc_std = np.std(fixsize_vect)\n",
    "    \n",
    "    return [sacc_mean, sacc_var, sacc_std]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saccade Direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sacc_dir(fix_array,r):\n",
    "    \n",
    "    dir_dict = {\"sacc-up\":0, \"sacc-up-right\":0, \"sacc-right\":0, \"sacc-down-right\":0, \"sacc-up-down\": 0, \"sacc-down-left\":0, \"sacc-left\":0, \"sacc-left-up\":0}\n",
    "    compass_brackets = [\"sacc-up\", \"sacc-up-right\", \"sacc-right\", \"sacc-down-right\", \"sacc-up-down\", \"sacc-down-left\", \"sacc-left\", \"sacc-left-up\", \"sacc-up\"]\n",
    "    dir_arr = []\n",
    "    \n",
    "    #loop through sliding window of fixation array\n",
    "    for n in range(r, (len(fix_array) - r - 1)):\n",
    "\n",
    "        m_before_x = 0\n",
    "        m_before_y = 0\n",
    "        m_after_x = 0\n",
    "        m_after_y = 0\n",
    "\n",
    "        #find the mean coordinates of the sliding window\n",
    "        for i in range(1, r):\n",
    "            #m_before is the avg of r (sliding window) values \n",
    "            try:\n",
    "                m_before_x += fix_array[n-i, 0]/r\n",
    "                m_before_y += fix_array[n-i, 1]/r\n",
    "                m_after_x += fix_array[n+i,0]/r\n",
    "                m_after_y += fix_array[n+i, 1]/r\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        #difference between before and after means\n",
    "        deltaX = m_after_x - m_before_x\n",
    "        deltaY = m_after_y - m_before_y\n",
    "    \n",
    "        #calculating angle/direction on unit circle\n",
    "        degrees_temp = math.atan2(deltaX, deltaY)/math.pi*180\n",
    "\n",
    "        if degrees_temp<0:\n",
    "            degrees_final = 360 + degrees_temp\n",
    "        else:\n",
    "            degrees_final = degrees_temp\n",
    "    \n",
    "        #find index of which direction based on number (like hashing) cooresponding to compass brackets\n",
    "        if (math.isnan(degrees_final)):\n",
    "                continue\n",
    "        else:\n",
    "            compass_lookup = round(degrees_final/45)\n",
    "            direction = compass_brackets[compass_lookup]\n",
    "\n",
    "            #increase count of direction\n",
    "            dir_dict[direction] +=1\n",
    "            dir_arr.append(direction)\n",
    "\n",
    "    return dir_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sacc_compl_dir(dir_arr, compass_brackets):\n",
    "    \n",
    "    compl_dict = {\"follow-saccade\": 0, \"neighbouring-saccade\": 0, \"opposite-saccade\": 0}\n",
    "    \n",
    "    #loop through array of directions (ordered by time)\n",
    "    for i in range(1,len(dir_arr)):\n",
    "        \n",
    "        curr = dir_arr[i]\n",
    "        prev = dir_arr[i-1]\n",
    "        \n",
    "        #index of saccade direction\n",
    "        curr_dirind= compass_brackets.index(curr)\n",
    "        prev_dirind= compass_brackets.index(prev)\n",
    "\n",
    "        ind_diff = abs(curr_dirind-prev_dirind)\n",
    "        \n",
    "        #opposite\n",
    "        if (ind_diff == 4):\n",
    "            compl_dict[\"opposite-saccade\"] +=1\n",
    "        \n",
    "        #neighboring\n",
    "        if (ind_diff == 1):\n",
    "            compl_dict[\"neighbouring-saccade\"] +=1\n",
    "        \n",
    "        #following\n",
    "        if (curr == prev):\n",
    "            compl_dict[\"follow-saccade\"] +=1\n",
    "            \n",
    "    return (compl_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixation Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns fixation duration mean, variance, and standard deviation\n",
    "def fix_dura(fix_array):\n",
    "    time_array = []\n",
    "    \n",
    "    #loop through array of fixations\n",
    "    for i in range(1,len(fix_array)):\n",
    "        #get current and previous time stamps (of peaks)\n",
    "        #fixation is in between\n",
    "        \n",
    "        time_curr = fix_array[i, 2]\n",
    "        time_prev = fix_array[i-1, 2]\n",
    "        \n",
    "        time_diff = time_curr-time_prev\n",
    "        time_array.append(time_diff)\n",
    "    \n",
    "    #returns array of all fixation durations\n",
    "    time_array = np.asarray(time_array)\n",
    "        \n",
    "    dura_mean = np.mean(time_array)\n",
    "    dura_var = np.var(time_array)\n",
    "    dura_std = np.std(time_array)\n",
    "                \n",
    "    return [dura_mean, dura_var, dura_std]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixation Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of fixations over 1000 ms (1s)\n",
    "#count fixations per second\n",
    "def fixa_rate(fix_array): \n",
    "    return len(fix_array)/1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixation Slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#returns slope of x,y lin reg plot\n",
    "#def slope(fixation_df):\n",
    "def slope(fix_array):\n",
    "\n",
    "    try:\n",
    "        Xs = fix_array[0]\n",
    "        Ys = fix_array[1]\n",
    "\n",
    "        #slope equation\n",
    "        slope = (((np.mean(Xs) * np.mean(Ys)) - np.mean(Xs*Ys)) / ((np.mean(Xs)**2) - np.mean(Xs**2)))\n",
    "\n",
    "        return slope\n",
    "    except:\n",
    "        return float('nan')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixation Dispersion Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating 1D difference vector \n",
    "#m(after) - m(before) = difference in means of sliding windows\n",
    "#r = length of sliding windows\n",
    "\n",
    "#input is the array of x and y & value of sliding window\n",
    "def disp_area(fix_array): \n",
    "    try:\n",
    "        meanx = np.mean(fix_array, axis=0)[0]\n",
    "        meany = np.mean(fix_array, axis=0)[1]\n",
    "\n",
    "        disp_full = []\n",
    "\n",
    "        #run through array\n",
    "        for n in range(0, (len(fix_array)-1)):\n",
    "            currx = fix_array[n, 0]\n",
    "            curry = fix_array[n, 1]\n",
    "            diff_eq = math.sqrt((meanx - currx)**2 + (meany - curry)**2)\n",
    "\n",
    "            disp_full.append([diff_eq])\n",
    "\n",
    "        #entire array of dispersion distances\n",
    "        disp_full = np.asarray(disp_full)\n",
    "\n",
    "        #array of x,y,dist\n",
    "        out_arr = fix_array.copy()\n",
    "        out_arr = np.append(out_arr[:len(disp_full)], disp_full, 1)\n",
    "        #sort by distance in increasing order\n",
    "        out_arr = out_arr[out_arr[:,3].argsort()]\n",
    "        #disp_full = disp_full.sort(axis=1)\n",
    "\n",
    "        #find how many is 75% of data\n",
    "        outliers = int(.75 * len(fix_array))\n",
    "\n",
    "        #should be first 75% of data with shortest distance from mean\n",
    "        adjusted = out_arr[:][0:outliers+1]\n",
    "\n",
    "        #repeat steps with adjusted mean\n",
    "\n",
    "        #new mean using adjusted data\n",
    "        newmeanx = np.mean(adjusted, axis=0)[0]\n",
    "        newmeany = np.mean(adjusted, axis=0)[1]\n",
    "\n",
    "        disp_adj = []\n",
    "\n",
    "        #run through array\n",
    "        for n in range(0, (len(adjusted)-1)):\n",
    "            currx = adjusted[n, 0]\n",
    "            curry = adjusted[n, 1]\n",
    "            diff_eq = math.sqrt((newmeanx - currx)**2 + (newmeany - curry)**2)\n",
    "\n",
    "            disp_adj.append(diff_eq)\n",
    "\n",
    "        #get the area of the distances \n",
    "        #max,min y max min y\n",
    "\n",
    "        return np.mean(disp_adj)\n",
    "    except: \n",
    "        return float('nan')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixation count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns number of fixations\n",
    "def fix_count(fix_array):\n",
    "    try:\n",
    "        shape = np.shape(fix_array)\n",
    "        size_data = shape[0]\n",
    "        return size_data\n",
    "    except: \n",
    "        return float('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
